{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ml01': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c1608d49df37f7b5acfe6ac9cd4b1e25f5d21a475730e5f7d7024431f5524edd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Big 5 pred \n",
    "I big5.ipynb gjorde jeg noen konverteringer og visualiseringer.\n",
    "Nå skal vi prøve å lage prediktive modeller:\n",
    "- Dele datrasettet i train og test (Ikke dev her, siden ikke så seriøst)\n",
    "- Skalere data \n",
    "- Bruke scikit-learn til å finne beste modell-arkitektur og hyperparametre"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Unnamed: 0', 'race', 'age', 'engnat', 'gender', 'hand', 'source', 'country', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9', 'O10', 'E', 'N', 'A', 'C', 'O']\ndata values: 1.0 5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC, SVR, LinearSVR, LinearSVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "# Hente inn datatsettet, filtrere feil og utliggere alder\n",
    "df_data = pd.read_csv(\"b5_svar.csv\")\n",
    "df_data = df_data[df_data[\"gender\"].isin([1, 2]) &  df_data.age.isin(range(16,51))]\n",
    "spm_grupper = {\"E\": \"Extraversion\", \"A\": \"Agreeableness\", \"C\": \"Conscientiousness\", \"N\": \"Emotional Stability\", \"O\": \"Intellect/Imagination\"}\n",
    "five = ['N', 'C', 'E', 'A', 'O']\n",
    "spm_c = [c for c in df_data.columns if c[-1].isdigit() and not c.startswith(\"Unnamed\")] # De 50 spørsmålene\n",
    "print(list(df_data.columns))\n",
    "print(\"data values:\",df_data[spm_c].min().min(), df_data[spm_c].max().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Før filtrering 16979\nEtter filtrering 11479\nOK\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    7322\n",
       "2    1233\n",
       "3    1396\n",
       "4     782\n",
       "5     746\n",
       "Name: cc_5, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Take 2: Estimere på opprinnelsesland.\n",
    "# Forberede data for å estimere på opprinnelsesland\n",
    "\n",
    "cc5 = ['US', 'GB', 'IN', 'AU', 'CA']\n",
    "c_conv = {'US':1, 'GB':2, 'IN':3, 'AU':4, 'CA':5, 'other':0}\n",
    "\"\"\"\n",
    "Det fungerte dårlig med disse seks klassene.\n",
    "0    5500\n",
    "1    7322\n",
    "2    1233\n",
    "3    1396\n",
    "4     782\n",
    "5     746\n",
    " Prøver på bare US / Ikke US Binært.\n",
    "\"\"\"\n",
    "df_data[\"cc_5\"] = df_data[\"country\"].where(df_data[\"country\"].isin(cc5), \"other\")\n",
    "print(\"Før filtrering\", len(df_data))\n",
    "df_cc5 = df_data[df_data[\"cc_5\"] != \"other\"]\n",
    "print(\"Etter filtrering\", len(df_cc5))\n",
    "x = df_cc5[spm_c]\n",
    "y = df_cc5[\"cc_5\"].map(c_conv)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "print(\"OK\")\n",
    "\n",
    "y.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BernoulliNB : Modellen scorer -0.61 når den estimerer landtilhørighet.  Parametre: {'model__alpha': 0.1}\n",
      "LogisticRegression : Modellen scorer -0.66 når den estimerer landtilhørighet.  Parametre: {'model__C': 0.5, 'model__penalty': 'l2'}\n",
      "RandomForestClassifier : Modellen scorer -0.65 når den estimerer landtilhørighet.  Parametre: {'model__n_estimators': 100}\n",
      "LinearSVC : Modellen scorer -0.66 når den estimerer landtilhørighet.  Parametre: {}\n",
      "neural_network.MLPClassifier : Modellen scorer -0.66 når den estimerer landtilhørighet.  Parametre: {'model__alpha': 0.0001, 'model__hidden_layer_sizes': 100, 'model__learning_rate_init': 0.0001, 'model__solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Take 2 multiclass klassifisering uten \"other\"\n",
    "\n",
    "# Modeller som fungerer med kategoriske data\n",
    "# Brukte disse med seks landkategorier menfikke ikke noe ut av det\n",
    "modeller = [\n",
    "    {\"name\": \"BernoulliNB\", \"model\": BernoulliNB(), \n",
    "                    \"params\": {'model__alpha': [1, 0.1, 0.01, 0.001]}},\n",
    "\n",
    "    {\"name\": \"LogisticRegression\", \"model\": linear_model.LogisticRegression(multi_class='multinomial'),\n",
    "                    \"params\": {\"model__C\":[0.5, 1.0, 2.0, 10.0], \"model__penalty\": ['l1', 'l2', 'elasticnet', 'none']}},\n",
    "\n",
    "    {\"name\": \"RandomForestClassifier\", \"model\": RandomForestClassifier(),\n",
    "                    \"params\": {\"model__n_estimators\": [50,100,200, 400]}},\n",
    "     \n",
    "\n",
    "{\"name\": \"LinearSVC\", \"model\": LinearSVC(multi_class='crammer_singer'),\n",
    "                    \"params\": {}},\n",
    "\n",
    "    {\"name\": \"neural_network.MLPClassifier\", \"model\": MLPClassifier(learning_rate = 'invscaling'),\n",
    "                    \"params\": {\"model__hidden_layer_sizes\":[(100), (100,20)], \"model__solver\": ['sgd', 'adam'],\n",
    "                    \"model__alpha\": [0.0001, 0.001], \"model__learning_rate_init\":  [0.001, 0.0001]}}\n",
    "  ]\n",
    "   \n",
    "\n",
    "\n",
    "grids = {} # Collect individual pipelines\n",
    "\n",
    "for m in modeller: #Sjekke pat arameternavnene er riktige\n",
    "    given = set([p[7:] for p in m[\"params\"]])\n",
    "    pool = set(m[\"model\"].get_params())\n",
    "    assert given.issubset(pool), print(m[\"name\"],given, pool)\n",
    "\n",
    "for m in modeller:\n",
    "    steps = [('scaler', StandardScaler()), ('model', m[\"model\"]) ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    parameters = m[\"params\"]\n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid = parameters, cv=5, scoring = 'accuracy')\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(m[\"name\"],\": Modellen scorer %3.2f når den estimerer landtilhørighet. \" % -grid.score(x_test, y_test), \"Parametre:\", grid.best_params_)\n",
    "    with open (\"country_model2.txt\", \"a\") as wf:\n",
    "        wf.write(m[\"name\"]+\": Modellen scorer %3.2f når den estimerer landtilhørighet. \" % -grid.score(x_test, y_test)+ \"Parametre:\"+ str(grid.best_params_)+\"\\n\")\n",
    "    grids[m[\"name\"]] = grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Y 0    9657\n",
      "1    7322\n",
      "Name: cc_2, dtype: int64\n",
      "X size [679150, 169800]\n",
      "KNeighborsClassifier : Modellen scorer -0.60 når den estimerer landtilhørighet.  Parametre: {'model__n_neighbors': 7}\n",
      "GaussianProcessClassifier : Modellen scorer -0.59 når den estimerer landtilhørighet.  Parametre: {'model__max_iter_predict': 100}\n",
      "GaussianNB : Modellen scorer -0.61 når den estimerer landtilhørighet.  Parametre: {}\n",
      "RandomForestClassifier : Modellen scorer -0.58 når den estimerer landtilhørighet.  Parametre: {'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Take 3 Binær klassifisering\n",
    "c_conv2 = {'US':1, 'other':0}\n",
    "df_data[\"cc_2\"] = df_data[\"country\"].where(df_data[\"country\"]== \"US\", \"other\")\n",
    "x = df_data[spm_c]\n",
    "y = df_data[\"cc_2\"].map(c_conv)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "print(\"Y\", y.value_counts().sort_index())\n",
    "print(\"X size\", [x.size for x in [x_train, x_test]])\n",
    "\n",
    "\n",
    "\n",
    "modeller = [\n",
    "    {\"name\": \"KNeighborsClassifier\", \"model\": KNeighborsClassifier(), \n",
    "                    \"params\": {'model__n_neighbors': [3,5,7]}},\n",
    "\n",
    "    {\"name\": \"GaussianProcessClassifier\", \"model\": GaussianProcessClassifier(),\n",
    "                    \"params\": { \"model__max_iter_predict\": [100, 500, 1000]}},\n",
    "\n",
    "      {\"name\": \"GaussianNB\", \"model\": GaussianNB(), \n",
    "                     \"params\": {}},\n",
    "  \n",
    "    {\"name\": \"RandomForestClassifier\", \"model\": RandomForestClassifier(max_depth=5, max_features=1),\n",
    "                    \"params\": {\"model__n_estimators\": [50,100,200, 400]}},\n",
    "\n",
    "    {\"name\": \"neural_network.MLPClassifier\", \"model\": MLPClassifier(max_iter=1000),\n",
    "                    \"params\": {\"model__hidden_layer_sizes\":[(100),  (100,20)], \"model__solver\": ['sgd', 'adam'],\n",
    "                    \"model__alpha\": [0.0001, 0.001, 0.1, 1], \"model__learning_rate_init\":  [ 0.0001, 0.00001]}},\n",
    "\n",
    "    {\"name\": \"SVC\", \"model\": SVC(),\n",
    "                        \"params\": {\"model__C\":[0.005, 0.1,0.5, 1.0, 2.0, 5.0], \n",
    "                                    \"model__kernel\":[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                                    \"model__gamma\": [1,2,3,4,5]}},\n",
    "     ]\n",
    "\n",
    "   \n",
    "\n",
    "grids = {} # Collect individual pipelines\n",
    "\n",
    "for m in modeller: #Sjekke pat arameternavnene er riktige\n",
    "    given = set([p[7:] for p in m[\"params\"]])\n",
    "    pool = set(m[\"model\"].get_params())\n",
    "    assert given.issubset(pool), print(m[\"name\"],given, pool)\n",
    "\n",
    "for m in modeller:\n",
    "    steps = [('scaler', StandardScaler()), ('model', m[\"model\"]) ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    parameters = m[\"params\"]\n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid = parameters, cv=5, scoring = 'accuracy')\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(m[\"name\"],\": Modellen scorer %3.2f når den estimerer landtilhørighet. \" % -grid.score(x_test, y_test), \"Parametre:\", grid.best_params_)\n",
    "    with open (\"country_model2.txt\", \"a\") as wf:\n",
    "        wf.write(m[\"name\"]+\": Modellen scorer %3.2f når den estimerer landtilhørighet. \" % -grid.score(x_test, y_test)+ \"Parametre:\"+ str(grid.best_params_)+\"\\n\")\n",
    "    grids[m[\"name\"]] = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LM_Ridge : Modellen estmierer i snitt 6.3 år feil i alder. Parametre: {'model__alpha': 0.01, 'model__tol': 0.9}\n",
      "ElasticNet : Modellen estmierer i snitt 6.4 år feil i alder. Parametre: {'model__alpha': 0.5, 'model__l1_ratio': 0.2}\n",
      "BayesianRidge : Modellen estmierer i snitt 6.3 år feil i alder. Parametre: {'model__alpha_1': 1e-05, 'model__alpha_2': 1e-07, 'model__lambda_1': 1e-07}\n",
      "KernelRidge : Modellen estmierer i snitt 25.3 år feil i alder. Parametre: {'model__alpha': 0.1}\n",
      "GradientBoostingRegressor : Modellen estmierer i snitt 5.9 år feil i alder. Parametre: {'model__loss': 'lad', 'model__max_depth': 5}\n",
      "LinearSVR : Modellen estmierer i snitt 6.0 år feil i alder. Parametre: {'model__C': 1.0, 'model__epsilon': 0.0, 'model__tol': 0.0001}\n",
      "SVR : Modellen estmierer i snitt 5.8 år feil i alder. Parametre: {'model__C': 5, 'model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Take 1: Predikere alder bare utfra spørsmålene\n",
    "x = df_data[spm_c]\n",
    "y = df_data[\"age\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "\n",
    "#Scikit-learn pipeline\n",
    "\n",
    "# from sklearn.linear_model import ElasticNet, from sklearn.linear_model import BayesianRidge\n",
    "modeller = [\n",
    "    {\"name\": \"LM_Ridge\", \"model\": linear_model.Ridge(), \n",
    "                     \"params\": {'model__alpha': [0.01, 0.1, 0.3,0.5, 0.8], 'model__tol': [0.9, 0.5, 0.1, 0.01]}},\n",
    "    {\"name\": \"ElasticNet\", \"model\": linear_model.ElasticNet(), \n",
    "                    \"params\": {\"model__alpha\": [0.5,1.0, 1,4], \"model__l1_ratio\": [0.2, 0.5, 0.8]}},\n",
    "    {\"name\": \"BayesianRidge\", \"model\": linear_model.BayesianRidge(), \n",
    "     \"params\":{'model__alpha_1': [1e-5, 1e-6, 1e-7], 'model__alpha_2': [1e-5, 1e-6, 1e-7], 'model__lambda_1': [1e-5, 1e-6, 1e-7] }},\n",
    "    {\"name\": \"KernelRidge\", \"model\": KernelRidge(), \n",
    "                    \"params\": {\"model__alpha\": [0.1, 0.5,1.0, 2.0]}},   \n",
    "    {\"name\": \"GradientBoostingRegressor\", \"model\": GradientBoostingRegressor(), \n",
    "                    \"params\": {\"model__loss\":['ls', 'lad', 'huber' ],\"model__max_depth\": [2,3,4,5,6]}},  \n",
    "    {\"name\": \"LinearSVR\", \"model\": LinearSVR(), \n",
    "        \"params\": {\"model__epsilon\":[0.0, 0.001, 0.1, 2], \"model__tol\": [0.0001, 0.005], \"model__C\":[0.5, 1.0, 2.0, 10.0]}},  \n",
    "    {\"name\": \"SVR\",   \"model\": SVR(),\n",
    "        \"params\":{\"model__kernel\":['linear',  'rbf', 'sigmoid'], \"model__C\": [ 1, 5, 10, 3]}}\n",
    "    ]\n",
    "\n",
    "for m in modeller: #Sjekke pat arameternavnene er riktige\n",
    "    given = set([p[7:] for p in m[\"params\"]])\n",
    "    pool = set(m[\"model\"].get_params())\n",
    "    assert given.issubset(pool), print(m[\"name\"],given, pool)\n",
    "\n",
    "for m in modeller:\n",
    "    steps = [('scaler', StandardScaler()), ('model', m[\"model\"]) ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    parameters = m[\"params\"]\n",
    "    # print(parameters)\n",
    "    # print(m[\"model\"].get_params())\n",
    "    grid = GridSearchCV(pipeline, param_grid = parameters, cv=5, scoring = 'neg_mean_absolute_error')\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(m[\"name\"],\": Modellen estmierer i snitt %3.1f år feil i alder.\" % -grid.score(x_test, y_test), \"Parametre:\", grid.best_params_)\n",
    "    with open (\"age_model.txt\", \"a\") as wf:\n",
    "        wf.write(m[\"name\"]+\": Modellen estmierer i snitt %3.1f år feil i alder.\" % -grid.score(x_test, y_test)+ \"Parametre:\"+ str(grid.best_params_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Y 0    212\n1    357\ndtype: int64\nX shape [(455, 30), (114, 30)]\n"
     ]
    }
   ],
   "source": [
    "# Eksperimenter på binært med breast cancer datasettet\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "db = load_breast_cancer()\n",
    "x = db['data']\n",
    "y = db['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)\n",
    "print(\"Y\", pd.DataFrame(y).value_counts().sort_index())\n",
    "print(\"X shape\", [x.shape for x in [x_train, x_test]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trene modeller på breast cancer\n",
    "modeller = [\n",
    "    {\"name\": \"BernoulliNB\", \"model\": BernoulliNB(), \n",
    "                    \"params\": {'model__alpha': [1, 0.1, 0.01, 0.001]}},\n",
    "\n",
    "    {\"name\": \"LogisticRegression\", \"model\": linear_model.LogisticRegression(multi_class='multinomial'),\n",
    "                    \"params\": {\"model__C\":[0.5, 1.0, 2.0, 10.0], \"model__penalty\": ['l1', 'l2', 'elasticnet', 'none']}},\n",
    "\n",
    "    {\"name\": \"RandomForestClassifier\", \"model\": RandomForestClassifier(),\n",
    "                    \"params\": {\"model__n_estimators\": [50,100,200, 400]}},\n",
    "     \n",
    "\n",
    "{\"name\": \"LinearSVC\", \"model\": LinearSVC(multi_class='crammer_singer'),\n",
    "                    \"params\": {}},\n",
    "\n",
    "    {\"name\": \"neural_network.MLPClassifier\", \"model\": MLPClassifier(learning_rate = 'invscaling'),\n",
    "                    \"params\": {\"model__hidden_layer_sizes\":[(100), (100,20)], \"model__solver\": ['sgd', 'adam'],\n",
    "                    \"model__alpha\": [0.0001, 0.001], \"model__learning_rate_init\":  [0.001, 0.0001]}}\n",
    "  ]\n",
    "   \n",
    "\n",
    "\n",
    "grids = {} # Collect individual pipelines\n",
    "\n",
    "for m in modeller: #Sjekke pat arameternavnene er riktige\n",
    "    given = set([p[7:] for p in m[\"params\"]])\n",
    "    pool = set(m[\"model\"].get_params())\n",
    "    assert given.issubset(pool), print(m[\"name\"],given, pool)\n",
    "\n",
    "for m in modeller:\n",
    "    steps = [('scaler', StandardScaler()), ('model', m[\"model\"]) ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    parameters = m[\"params\"]\n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid = parameters, cv=5, )\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(m[\"name\"],\": Modellen scorer %3.2f . \" % -grid.score(x_test, y_test), \"Parametre:\", grid.best_params_)\n",
    "    with open (\"bc01.txt\", \"a\") as wf:\n",
    "        wf.write(m[\"name\"]+\": Modellen scorer %3.2f. \" % -grid.score(x_test, y_test)+ \"Parametre:\"+ str(grid.best_params_)+\"\\n\")\n",
    "    grids[m[\"name\"]] = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LM_ridge: 0.14040290516277312 0.013854181282183365\n",
      "SVR: 0.05937084613752271 0.04638912847902978\n"
     ]
    }
   ],
   "source": [
    "# Første utkast.\n",
    "\n",
    "\n",
    "model= linear_model.Ridge(alpha=.5)\n",
    "scores = cross_val_score(model, x, y, cv=7)\n",
    "print(\"LM_ridge:\", scores.mean(), scores.std())\n",
    "\n",
    "model = LinearSVR(random_state=0, tol=1e-05)\n",
    "scores = cross_val_score(model, x, y, cv=7)\n",
    "print(\"SVR:\", scores.mean(), scores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "write() takes exactly one argument (2 given)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d663c6b70c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"age_model.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mwf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Overskrift\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"neste\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: write() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "# Kladd\n",
    "\n",
    "a = {1:10, 2:22}\n",
    "b = {1:11, 2:220}\n",
    "# len([n for n in a if n not in b])\n",
    "# len(set(a).intersection(b)) == len(a)\n",
    "set(a).issubset(set(b))\n"
   ]
  }
 ]
}